# âœ¨âœ¨VLADBenchâœ¨âœ¨: Fine-Grained Evaluation of Large Vision-Language Models in Autonomous Driving 

<div align="center">

![VLADBench](https://img.shields.io/badge/Dataset-VLADBench-blue)
![VQA](https://img.shields.io/badge/Task-Autonomous--Driving--QA-red) 
![Multi-Modal](https://img.shields.io/badge/Modal-Image/Video-red)  
![Models](https://img.shields.io/badge/Models-Open--Source-green) 
![Models](https://img.shields.io/badge/Models-Closed--Source-green) 
![Models](https://img.shields.io/badge/Models-Domain--Specified-green) 

</div>
<div align="center" style="font-size: 22px; margin-top: 20px; margin-bottom: 20px; line-height: 2.5;">
  <a href="https://arxiv.org/pdf/2503.21505">ðŸ“– arXiv Paper</a> &nbsp;&nbsp;&nbsp;&nbsp;
  <a href="https://huggingface.co/datasets/depth2world/VLADBench">ðŸ¤— Dataset</a>
</div>


# Overview
<p align="center">
    <img src="./asset/sun.png" width="100%" height="100%">
</p>


# Benchmark
Coming soon
